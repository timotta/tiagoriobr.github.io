<?xml version="1.0" encoding="UTF-8"?>
<feed xmlns="https://www.w3.org/2005/Atom">
    <title>tiago.rio.br</title>
    
    <link rel="alternate" href="/" />
    <link rel="self" href="/feed.xml" type="application/atom+xml" />
    <id>/</id>
    <updated>2023-09-23T13:37:03Z</updated>

    <author>
        <name>Tiago Albineli Motta</name>
        
        <uri>/</uri>
    </author>

    
        <entry>
            <title>Collecting data to identify data collect</title>
            <link rel="alternate" href="/work/olxbrasil/trustandsafety/collecting-data-to-indentify-data-collection/" type="text/html" />
            <id>/work/olxbrasil/trustandsafety/collecting-data-to-indentify-data-collection/</id>
            <updated>2023-08-19T13:36:00Z</updated>

            <summary type="html">This is the story of how we managed to prevent &amp;ldquo;data collect&amp;rdquo; fraud through a data collection!</summary>
            <content type="html">&lt;p&gt;This is the story of how we managed to prevent &amp;ldquo;data collect&amp;rdquo; fraud through a data collection!&lt;/p&gt;

&lt;p&gt;It happened in mid-2022. At the time, I had already been working for a year and a half in the Trust &amp;amp; Safety area at OLX Brasil, and we had achieved significant success in reducing fraud attempts. Especially in a type of fraud known as &amp;ldquo;False Payment&amp;rdquo;. In fact, another type of fraud known as &amp;ldquo;Data Collect&amp;rdquo; has since become the highest number of reported cases.&lt;/p&gt;

&lt;p&gt;The problem with this other type of fraud is that the behavior of the fraudsters was very similar to that of another type of malicious user: the spammer. A modeling to identify this type of fraudster, done a few months earlier, failed for this reason. We were unable to separate the spammer from a fraudster of this type of fraud in any way.&lt;/p&gt;

&lt;p&gt;Then you may ask me, why not prevent both characters with the same model?&lt;/p&gt;

&lt;p&gt;The approach we had towards spammers was quite different from the approach towards a fraudster. I cannot go into detail about how these approaches because confidentiality is part of security, and making it public can assist both groups in finding ways to circumvent. But trust me, it was very important to distinguish our actions in dealing with these two groups.&lt;/p&gt;

&lt;p&gt;We were at an impasse, our last model was actually doing a good job at accurately distinguishing between legitimate users and these two groups, but we couldn&amp;rsquo;t put it into production for making automatic decisions. We were missing the ability to identify which micro behaviors set one group apart from the other, and there was only one team in the company that could help us with that: the monitoring team.&lt;/p&gt;

&lt;p&gt;This team was a multidisciplinary team of fraud identification experts in the company. They were responsible for manually reviewing samples from automated models and operational team decisions regarding reports that were not handled automatically.&lt;/p&gt;

&lt;p&gt;We spoke with this team in an attempt to find any new criteria that could help us separate the cases. The conversation proved to be a not-so-effective tool, as the developers and monitors didn&amp;rsquo;t seem to speak the same language. We couldn&amp;rsquo;t objectively map out these determining factors through these unstructured conversation.&lt;/p&gt;

&lt;p&gt;To address this, we created a spreadsheet with a large sample of cases that the not so good model had identified as fraud (and within those cases, there were many spams) and added two columns: one to indicate whether it was fraud or spam, and another for free text where the operator could explain the reasons behind their conclusion. This spreadsheet was sent to the monitoring team for completion.&lt;/p&gt;

&lt;p&gt;The result could not be more satisfactory. In the first lines, the free text column started off more &amp;ldquo;poetic&amp;rdquo; and gradually, the repetitive pattern of the groups caused the monitors to write in a more concise and even repetitive manner, generating a clear pattern on new criteria that we could adopt for the machine learning model.&lt;/p&gt;

&lt;p&gt;Our data collection had worked. Our data collection had been successful.&lt;/p&gt;

&lt;p&gt;These pieces of information generated new feature calculations for a new machine learning model training. We sent new samples of the results from this new model for monitoring evaluation, which could assure us of high accuracy. For a few weeks, we kept the artifact in production without taking any action, only logging, just to monitor if the generated result would reflect the results obtained in the offline evaluation. Everything went smoothly.&lt;/p&gt;

&lt;p&gt;In the weeks after enabling the new model to take actions against the fraudsters, we experienced an average decrease of 33% in &amp;ldquo;Data collect&amp;rdquo; frauds per week. Another type of fraud, known as &amp;ldquo;False Sale&amp;rdquo;, also saw a 25% decrease, as it relies on a more complicated social engineering involving the execution of &amp;ldquo;Data collect&amp;rdquo; fraud at first place to be effective.&lt;/p&gt;

&lt;p&gt;So we data collected to avoid data collect successfully.&lt;/p&gt;
</content>
        </entry>
    
        <entry>
            <title>The fantastic widget factory</title>
            <link rel="alternate" href="/work/globocom/webmedia/the-fantastic-widget-factory/" type="text/html" />
            <id>/work/globocom/webmedia/the-fantastic-widget-factory/</id>
            <updated>2023-04-29T14:16:00Z</updated>

            <summary type="html">This is the story of how we performed a series of workarounds to overcome the rigidity of an extremely controlled production environment, and successfully deliver a product and platform solution.</summary>
            <content type="html">&lt;p&gt;This is the story of how we performed a series of workarounds to overcome the rigidity of an extremely controlled production environment, and successfully deliver a product and platform solution.&lt;/p&gt;

&lt;p&gt;The case occurred in mid-2006 at Globo.com. At that time, the portal was divided into several independent sites, such as G1, GloboEsporte, Ego, among others. Generally, these sites displayed only text news, and all video assets were concentrated on another site called GMC, Globo Media Center.&lt;/p&gt;

&lt;p&gt;Our initial goal was to break down the silo in relation to video content, allowing developers from other sites to offer GMC registered videos in a simple and standardized way. At the time, an API was already available (known as WebmediaAPI), but it did not standardize the display of these content offerings, which would require additional effort from these teams for implementation.&lt;/p&gt;

&lt;p&gt;The solution we proposed would be to develop standardized visual widgets. These widgets would bring offers of various types such as recent videos, most viewed videos, best-rated videos, with the possibility of applying various filters and layout options. In this way, it would only be necessary to instantiate the widget into backend code page to offer video content in any Globo.com website.&lt;/p&gt;

&lt;p&gt;Here comes our first issue: At that time, Globo.com websites used a platform called Vignette, which made all its content static during the publication of homepages and articles. In other words, the news articles were static HTML generated after each publication, and the homepages were the same. Any changes to the page needed an editor to publish them for them to be displayed.&lt;/p&gt;

&lt;p&gt;This went against the dynamic nature of video content. How to maintain dynamically ordered content such as &amp;ldquo;most viewed&amp;rdquo; on a static HTML page? One way would be to use server-side includes, since the static files were served by Apache.&lt;/p&gt;

&lt;p&gt;Unfortunately, there were many restrictions to make any changes to the infrastructure at globo.com in 2006. To achieve this, we would need a lot of persuasion, meetings, presentations and one-on-one conversations, with no guarantee of success. We did not have the necessary time or social skills required for this goal. But we had a lot of creativity!&lt;/p&gt;

&lt;p&gt;So we decided to make these widgets on the client side. However, cross-domain requests to obtain information from WebmediaApi would only be possible if we could provide the necessary CORS headers. But to do this, changes to the infrastructure would also be necessary, as the application server (Apache) in front of WebmediaApi was also rigid, beyond our control, and exchanged all headers.&lt;/p&gt;

&lt;p&gt;Our solution was to allow WebmediaApi to return javascript call to a callback function instead of the json content. We then had a JavaScript with the widget code, which included another &amp;ldquo;JavaScript&amp;rdquo; that was the WebmediaAPI call with the name of a dynamic function as a parameter. This function was &amp;ldquo;printed&amp;rdquo; in the API response as a function call to finally render the chosen and customized widget.&lt;/p&gt;

&lt;p&gt;There was even a timeout control in case the callback took too long to respond.&lt;/p&gt;

&lt;p&gt;This solved our problem and after a few sprints, we created a true widget factory. Needs and ideas would come, and we would generate the necessary widgets and filters on WebmediaApi. It was a success. So much so, that the standardized layout of the widgets created the need to update the GMC, the aggregator site for all videos, to use the same layouts standards. Thus, Globo VÃ­deos was born, the successor to GMC.&lt;/p&gt;

&lt;p&gt;But there was a catch&amp;hellip;&lt;/p&gt;

&lt;p&gt;At that time, Google did not index pages rendered via JavaScript. And we needed at least Globo Videos to remain server-side rendered so that we wouldn&amp;rsquo;t lose relevance in organic searches.&lt;/p&gt;

&lt;p&gt;The solution: we started rendering javascript widgets on the server. Since everything in Vignette was java, we had to render using Rhino (if I&amp;rsquo;m not mistaken, before java 1.5 it was only possible to render javascript in the JVM through this lib).&lt;/p&gt;

&lt;p&gt;To maintain the freshness of the data, the Globo VÃ­deos homepage began to be rendered on the server every X period of time. I don&amp;rsquo;t remember if this automatic publication was done via cron or some Vignette tool, but the point is that static HTML began to be generated frequently, with the HTML of the widgets. However, the video pages continued to display client-side widgets as it would be impractical to render millions of HTML frequently.&lt;/p&gt;

&lt;p&gt;There was an added complexity to this solution as the process responsible for generating static HTML files on Globo.com was running on a WebLogic server. Although our server-side JavaScript rendering solution worked seamlessly in all other environments, including local, staging, and QA, it failed to function when deployed to production. After extensive debugging efforts, we discovered that the WebLogic version used in production differed from the other environments and contained an older Rhino version that superseded our newer one. To ensure proper widget rendering, we needed to execute the code by instantiating another classloader that loaded the correct Rhino jar version, which we successfully accomplished.&lt;/p&gt;

&lt;p&gt;In the end, we were able to develop a client-side widget platform that empowers websites to offer videos independently and consistently, without having to duplicate code. Furthermore, we devised a server-side rendered video product that can be easily indexed by Google. These achievements were made possible by implementing a series of three engineering workarounds.&lt;/p&gt;
</content>
        </entry>
    
</feed>
